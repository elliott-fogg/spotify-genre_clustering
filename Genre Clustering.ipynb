{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of genres in the Spotify dataset (>5000). We'd like to see if the Spotify Audio features can be used to differentiate between different genres, but to do this we need to know that there is a distinct difference between the genres that we choose to compare. (For example, there is probably a distinct difference between the genres of Dubstep and Classical Piano, but probably less so between Rock and Alternative Rock).\n",
    "\n",
    "To this end, we are going to attempt to cluster the genres into similar groups, and have a look at how homogenous the audio features are within some of the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:51:52.366843Z",
     "start_time": "2021-11-30T18:51:52.347864Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# import seaborn\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# import sklearn\n",
    "# from sklearn.cluster import KMeans, SpectralCoclustering, AgglomerativeClustering\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "# from sklearn.manifold import TSNE\n",
    "# import shared_functions as sf\n",
    "# import clustergrammer2 as cg\n",
    "# from clustergrammer2 import net\n",
    "# from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for preprocessed Pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:17.837969Z",
     "start_time": "2021-11-30T18:39:17.824979Z"
    }
   },
   "outputs": [],
   "source": [
    "load_from_source = True\n",
    "if os.path.isfile(\"genre_counts.pkl\") and os.path.isfile(\"sparse_normed_genre_links.pkl\"):\n",
    "    load_from_source = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from Original Source\n",
    "Skip this if the required Pickle files are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:26.068891Z",
     "start_time": "2021-11-30T18:39:17.839897Z"
    }
   },
   "outputs": [],
   "source": [
    "if load_from_source:\n",
    "    data = json.load(open(\"../all_artist_info.json\", \"r\"))\n",
    "    data_list = []\n",
    "    for key in data:\n",
    "        data_list.append((key,\n",
    "                          data[key][\"id\"],\n",
    "                          data[key][\"name\"],\n",
    "                          data[key][\"followers\"],\n",
    "                          data[key][\"popularity\"],\n",
    "                        \", \".join(data[key][\"genres\"])))\n",
    "    data_df = pd.DataFrame(data_list)\n",
    "    data_df.columns = [\"orig_id\", \"id\", \"name\", \"followers\", \"popularity\", \"genres\"]\n",
    "    data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Genre Counts and Co-occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:27.619666Z",
     "start_time": "2021-11-30T18:39:26.070886Z"
    }
   },
   "outputs": [],
   "source": [
    "if load_from_source:\n",
    "    genre_counts = {}\n",
    "    genre_links = {}\n",
    "    for row in data_df[\"genres\"]:\n",
    "        genres = row.split(\", \")\n",
    "        if len(genres) > 1:\n",
    "            for g1 in genres:\n",
    "                if g1 not in genre_links:\n",
    "                    genre_links[g1] = {}\n",
    "                for g2 in genres:\n",
    "                    if g2 not in genre_links[g1]:\n",
    "                        genre_links[g1][g2] = 0\n",
    "                    genre_links[g1][g2] += 1\n",
    "\n",
    "                if g1 not in genre_counts:\n",
    "                    genre_counts[g1] = 0\n",
    "                genre_counts[g1] += 1\n",
    "\n",
    "    normed_genre_links = {}\n",
    "    for g1 in genre_links:\n",
    "        normed_genre_links[g1] = {}\n",
    "        total_count = genre_links[g1][g1]\n",
    "        for g2 in genre_links[g1]:\n",
    "            normed_genre_links[g1][g2] = genre_links[g1][g2]/total_count\n",
    "\n",
    "    normed_genre_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data to Pickle files\n",
    "\n",
    "### Convert to Sparse Matrix and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:35.541521Z",
     "start_time": "2021-11-30T18:39:27.621656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>early us punk</th>\n",
       "      <th>synth punk</th>\n",
       "      <th>pub rock</th>\n",
       "      <th>punk</th>\n",
       "      <th>punk 'n' roll</th>\n",
       "      <th>punk blues</th>\n",
       "      <th>classic rock</th>\n",
       "      <th>permanent wave</th>\n",
       "      <th>rock</th>\n",
       "      <th>skate punk</th>\n",
       "      <th>...</th>\n",
       "      <th>disney russian</th>\n",
       "      <th>mgp</th>\n",
       "      <th>musique traditionnelle comorienne</th>\n",
       "      <th>lagu maluku</th>\n",
       "      <th>mindfulness</th>\n",
       "      <th>tamil worship</th>\n",
       "      <th>classic konkani pop</th>\n",
       "      <th>konkani pop</th>\n",
       "      <th>sound effects</th>\n",
       "      <th>malawian folk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>early us punk</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>0.045283</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synth punk</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub rock</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128302</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.108280</td>\n",
       "      <td>0.029070</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punk</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.146497</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.624277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punk 'n' roll</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.083019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5528 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               early us punk  synth punk  pub rock      punk  punk 'n' roll  \\\n",
       "early us punk       1.000000    0.030303  0.053030  0.045283       0.016393   \n",
       "synth punk          0.038462    1.000000  0.000000  0.007547       0.000000   \n",
       "pub rock            0.269231    0.000000  1.000000  0.128302       0.032787   \n",
       "punk                0.461538    0.060606  0.257576  1.000000       0.180328   \n",
       "punk 'n' roll       0.076923    0.000000  0.030303  0.083019       1.000000   \n",
       "\n",
       "               punk blues  classic rock  permanent wave      rock  skate punk  \\\n",
       "early us punk    0.063694      0.002907        0.009091  0.001773    0.011561   \n",
       "synth punk       0.006369      0.000000        0.000000  0.000000    0.000000   \n",
       "pub rock         0.108280      0.029070        0.018182  0.017730    0.000000   \n",
       "punk             0.146497      0.011628        0.072727  0.028369    0.624277   \n",
       "punk 'n' roll    0.101911      0.000000        0.000000  0.000000    0.069364   \n",
       "\n",
       "               ...  disney russian  mgp  musique traditionnelle comorienne  \\\n",
       "early us punk  ...             0.0  0.0                                0.0   \n",
       "synth punk     ...             0.0  0.0                                0.0   \n",
       "pub rock       ...             0.0  0.0                                0.0   \n",
       "punk           ...             0.0  0.0                                0.0   \n",
       "punk 'n' roll  ...             0.0  0.0                                0.0   \n",
       "\n",
       "               lagu maluku  mindfulness  tamil worship  classic konkani pop  \\\n",
       "early us punk          0.0          0.0            0.0                  0.0   \n",
       "synth punk             0.0          0.0            0.0                  0.0   \n",
       "pub rock               0.0          0.0            0.0                  0.0   \n",
       "punk                   0.0          0.0            0.0                  0.0   \n",
       "punk 'n' roll          0.0          0.0            0.0                  0.0   \n",
       "\n",
       "               konkani pop  sound effects  malawian folk  \n",
       "early us punk          0.0            0.0            0.0  \n",
       "synth punk             0.0            0.0            0.0  \n",
       "pub rock               0.0            0.0            0.0  \n",
       "punk                   0.0            0.0            0.0  \n",
       "punk 'n' roll          0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 5528 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame and fill all NA values with 0 (as that's what they should be)\n",
    "df = pd.DataFrame(normed_genre_links).fillna(0)\n",
    "\n",
    "# Convert to a Sparse Array, which makes it much smaller if we save it as a Pickle file\n",
    "df = df.astype(pd.SparseDtype(\"float\", 0))\n",
    "\n",
    "# Make the Columns symmetrical to the Index (not values will not be symmetrical, only labels)\n",
    "df = df[list(df.index)]\n",
    "\n",
    "# Save the DataFrame as a Pickle file for future use\n",
    "df.to_pickle(\"sparse_normed_genre_links.pkl\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Genre Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:35.572393Z",
     "start_time": "2021-11-30T18:39:35.543475Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(genre_counts).to_pickle(\"genre_counts.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Pickle Files\n",
    "Just to make sure this runs regardless of where the data comes from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:36.215528Z",
     "start_time": "2021-11-30T18:39:35.575386Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"sparse_normed_genre_links.pkl\")\n",
    "genre_counts = pd.read_pickle(\"genre_counts.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check parameters of the Data\n",
    "\n",
    "Have a quick look at some relevant stats about the data\n",
    "\n",
    "### Sparsity\n",
    "What percentage of the DataFrame is just zero-values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:37.049638Z",
     "start_time": "2021-11-30T18:39:36.219285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 99.5209%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sparsity: {round((df == 0).values.flatten().mean() * 100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:37.629467Z",
     "start_time": "2021-11-30T18:39:37.052583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of genres: 5528\n",
      "Maximum number of connections: 315 (art pop)\n",
      "Minimum number of connections: 2 (>1 so every genre has at least 1 connection as well as itself)\n",
      "Median number of connections: 16.0\n",
      "Mean number of connections: 26.482272069464543\n"
     ]
    }
   ],
   "source": [
    "connection_list = (df != 0).sum()\n",
    "print(f\"Total number of genres: {len(connection_list)}\")\n",
    "print(f\"Maximum number of connections: {connection_list.max()} ({connection_list[connection_list == connection_list.max()].index[0]})\")\n",
    "print(f\"Minimum number of connections: {connection_list.min()} (>1 so every genre has at least 1 connection as well as itself)\")\n",
    "print(f\"Median number of connections: {connection_list.median()}\")\n",
    "print(f\"Mean number of connections: {connection_list.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Clustering\n",
    "The Co-occurrence matrix is very sparse, which seems to imply that not all genres are actually connected with each other. Can we form clusters by just grouping together any genres that are linked at all, or will that devolve into one large cluster just through a few outliers being linked with everything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:37.644998Z",
     "start_time": "2021-11-30T18:39:37.632032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "a = set([1, 2, 3])\n",
    "n = set([3, 4, 5])\n",
    "d = set([5, 6, 7])\n",
    "print(set.union(*[a, n, d],[8, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:39.092449Z",
     "start_time": "2021-11-30T18:39:37.647991Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_genre_groups(gmap):\n",
    "    groups = []\n",
    "    \n",
    "    for base_genre in gmap:\n",
    "        r_genres = set(gmap[base_genre].keys())\n",
    "        matches = []\n",
    "        \n",
    "        for i in range(len(groups)):\n",
    "            # If the group has any common elements, group them together\n",
    "            if not (r_genres.isdisjoint(groups[i])):\n",
    "                groups[i] = groups[i].union(r_genres)\n",
    "                matches.append(i)\n",
    "        \n",
    "        if len(matches) > 0:\n",
    "            untouched_groups = [groups[i] for i in range(len(groups)) if i not in matches]\n",
    "            merged_group = set.union(*[groups[i] for i in matches], r_genres)\n",
    "            groups = untouched_groups + [merged_group]\n",
    "        \n",
    "        else:\n",
    "            # If no groups with common elements were found, create a new group\n",
    "            groups.append(r_genres)\n",
    "        \n",
    "    return groups\n",
    "\n",
    "output = create_genre_groups(normed_genre_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:40.538066Z",
     "start_time": "2021-11-30T18:39:39.094125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "5523\n"
     ]
    }
   ],
   "source": [
    "for g in create_genre_groups(normed_genre_links):\n",
    "    print(len(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Co-occurrence Threshold\n",
    "\n",
    "Okay, that didn't really work. We've ended up splitting off a whole 5 genres, and are left with a central supercluster of 5523 genres. It looks like the genres are generally too interconnected. But maybe we can start cutting some of those connections to try and break this down.\n",
    "\n",
    "What happens if we apply a threshold (e.g. for two genres to count as \"related\" their co-occurrence has to be above a certain value)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:39:40.646501Z",
     "start_time": "2021-11-30T18:39:40.540066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 < C <= 0.1: 80.74%\n",
      "0.1 < C <= 0.2: 10.2%\n",
      "0.2 < C <= 0.3: 3.52%\n",
      "0.3 < C <= 0.4: 2.05%\n",
      "0.4 < C <= 0.5: 1.27%\n",
      "0.5 < C <= 0.6: 0.73%\n",
      "0.6 < C <= 0.7: 0.55%\n",
      "0.7 < C <= 0.8: 0.41%\n",
      "0.8 < C <= 0.9: 0.24%\n",
      "0.9 < C <= 1.0: 0.31%\n"
     ]
    }
   ],
   "source": [
    "total_links = 0\n",
    "link_count = {i: 0 for i in range(10)}\n",
    "for g in normed_genre_links:\n",
    "    for rg in normed_genre_links[g]:\n",
    "        # Skip comparing to itself\n",
    "        if g == rg:\n",
    "            continue\n",
    "        total_links += 1\n",
    "        i = 0\n",
    "        while (i+1)/10 < normed_genre_links[g][rg]:\n",
    "            i += 1\n",
    "        link_count[i] += 1\n",
    "        \n",
    "for n in link_count:\n",
    "    link_count[n] = round(link_count[n] / total_links * 100, 2)\n",
    "    \n",
    "for val, perc in link_count.items():\n",
    "    print(f\"{val/10} < C <= {(val+1)/10}: {perc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this looks more promising. With a large percentage of co-occurrences already at very low rates, we should be able to eliminate most of them by applying a low threshold that doesn't remove too much of the existing clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:15.200315Z",
     "start_time": "2021-11-30T18:52:04.104986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "[(1, 4), (2, 2), (3, 2), (4, 1), (5, 1), (5505, 1)]\n",
      "\n",
      "0.2\n",
      "[(1, 175), (2, 52), (3, 16), (4, 10), (5, 3), (7, 1), (8, 2), (9, 1), (12, 1), (5102, 1)]\n",
      "\n",
      "0.3\n",
      "[(1, 684), (2, 192), (3, 63), (4, 42), (5, 20), (6, 13), (7, 3), (8, 6), (9, 5), (10, 4), (11, 4), (12, 4), (13, 4), (14, 2), (15, 2), (17, 2), (19, 1), (22, 1), (23, 1), (24, 1), (25, 1), (29, 1), (30, 1), (35, 1), (38, 1), (56, 1), (74, 1), (129, 1), (3031, 1)]\n",
      "\n",
      "0.4\n",
      "[(1, 1324), (2, 326), (3, 112), (4, 69), (5, 39), (6, 18), (7, 12), (8, 18), (9, 10), (10, 8), (11, 6), (12, 9), (13, 4), (14, 8), (15, 4), (16, 4), (17, 3), (18, 4), (19, 3), (20, 2), (21, 2), (22, 2), (24, 2), (28, 1), (29, 1), (30, 1), (37, 1), (39, 1), (41, 1), (44, 1), (49, 1), (51, 1), (53, 1), (67, 1), (83, 1), (88, 1), (102, 1), (120, 1), (133, 1), (429, 1)]\n",
      "\n",
      "0.5\n",
      "[(1, 1894), (2, 388), (3, 153), (4, 97), (5, 44), (6, 30), (7, 15), (8, 10), (9, 17), (10, 5), (11, 13), (12, 16), (13, 3), (14, 3), (15, 3), (16, 9), (17, 1), (18, 2), (19, 2), (20, 2), (26, 1), (27, 1), (30, 3), (31, 1), (32, 1), (36, 1), (39, 1), (44, 1), (47, 1), (52, 1), (63, 1)]\n",
      "\n",
      "0.6\n",
      "[(1, 2795), (2, 468), (3, 164), (4, 70), (5, 47), (6, 30), (7, 15), (8, 10), (9, 11), (10, 9), (11, 5), (12, 2), (14, 2), (15, 2), (16, 2), (20, 1), (23, 1), (24, 1)]\n",
      "\n",
      "0.7\n",
      "[(1, 3576), (2, 453), (3, 146), (4, 56), (5, 22), (6, 10), (7, 6), (8, 8), (9, 4), (10, 3), (12, 2), (18, 1)]\n",
      "\n",
      "0.8\n",
      "[(1, 4200), (2, 375), (3, 98), (4, 39), (5, 9), (6, 7), (7, 1), (8, 1), (11, 1), (15, 1)]\n",
      "\n",
      "0.9\n",
      "[(1, 4770), (2, 249), (3, 47), (4, 17), (5, 5), (6, 1), (9, 1), (11, 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def apply_threshold(gmap, threshold):\n",
    "    trimmed_gmap = {}\n",
    "    for genre in gmap:\n",
    "        trimmed_gmap[genre] = {}\n",
    "        for related_genre in gmap[genre]:\n",
    "            if gmap[genre][related_genre] >= threshold:\n",
    "                trimmed_gmap[genre][related_genre] = gmap[genre][related_genre]\n",
    "    return trimmed_gmap\n",
    "\n",
    "\n",
    "# def get_group_sizes_from_threshold(gmap, t):\n",
    "#     threshold_coocs = apply_threshold(gmap, t)\n",
    "#     threshold_groups = get_groups(threshold_coocs)\n",
    "#     group_sizes = sorted([len(v) for v in threshold_groups], reverse=True)\n",
    "#     return group_sizes\n",
    "    \n",
    "\n",
    "for t in range(1, 10):\n",
    "    threshold = t/10\n",
    "    print(threshold)\n",
    "    trimmed_genre_links = apply_threshold(normed_genre_links, threshold)\n",
    "    genre_groups = create_genre_groups(trimmed_genre_links)\n",
    "    group_sizes = [len(g) for g in genre_groups]\n",
    "    print(sorted(Counter(group_sizes).items()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.852402Z",
     "start_time": "2021-11-30T18:52:15.202307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'swedish trap pop', 'swedish drill', 'swedish trap', 'swedish hip hop', 'swedish gangsta rap'}\n",
      "\n",
      "{'sarod', 'carnatic instrumental', 'hindustani instrumental', 'indian percussion', 'hindustani vocal', 'khayal', 'carnatic vocal', 'carnatic', 'veena', 'indian classical', 'hindustani classical'}\n",
      "\n",
      "{'sinhala rap', 'sinhala pop', 'sinhala indie', 'classic sinhala pop', 'sinhala edm'}\n",
      "\n",
      "{'salsa international', 'tropical', 'salsa', 'combos nacionales'}\n",
      "\n",
      "{'barnemusikk', 'hollywood', 'eventyr', 'disney norsk'}\n",
      "\n",
      "{'oromo pop', 'tigrigna pop', 'ethiopian pop', 'amharic pop'}\n",
      "\n",
      "{'vintage radio show', 'oratory', 'reading', 'drama'}\n",
      "\n",
      "{'korean worship', 'world worship', 'chinese worship', 'japanese worship'}\n",
      "\n",
      "{'taiko', 'koto', 'japanese traditional', 'shakuhachi'}\n",
      "\n",
      "{'tamaulipas rap', 'mexican hip hop', 'indie campechano', 'rap underground mexicano'}\n",
      "\n",
      "{'utapri', 'actors', 'tsukiuta', 'a3', 'ensemble stars', 'starmyu', 'hypnosis mic', 'j-division', 'honeyworks'}\n",
      "\n",
      "{'latvian pop', 'classic latvian pop', 'latvian hip hop', 'bernu dziesmas'}\n",
      "\n",
      "{'cuento infantile', 'musica para ninos', 'cancion infantil mexicana', 'cancion infantil latinoamericana'}\n",
      "\n",
      "{'vispop', 'pinoy edm', 'pinoy trap', 'pinoy r&b'}\n",
      "\n",
      "{'dangdut', 'lagu aceh', 'lagu sunda', 'dangdut remix'}\n",
      "\n",
      "{'seiyu', 'anime', 'macross', 'gochiusa', 'shonen'}\n",
      "\n",
      "{'korean mask singer', 'k-pop girl group', 'k-pop', 'k-pop boy group'}\n",
      "\n",
      "{'erhu', 'pipa', 'guqin', 'cantonese traditional', 'guzheng', 'chinese traditional'}\n",
      "\n",
      "{'nepali indie', 'classic nepali pop', 'nepali pop', 'lok dohori'}\n",
      "\n",
      "{'german trap', 'german hip hop', 'afghan rap', 'hamburg hip hop'}\n",
      "\n",
      "{'latin alternative', 'comedia', 'mexican rock', 'rock en espanol'}\n",
      "\n",
      "{'vintage chinese pop', 'cantonese worship', 'classic cantopop', 'c-pop'}\n",
      "\n",
      "{'afrikaans gospel', 'south african country', 'kinderliedjies', 'afrikaans'}\n",
      "\n",
      "{'azontobeats', 'ugandan pop', 'gabonese pop', 'liberian pop', 'tanzanian pop'}\n",
      "\n",
      "{'jordanian pop', 'dabke', 'assyrian pop', 'syrian pop', 'arab pop'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trimmed_genre_links = apply_threshold(normed_genre_links, 0.9)\n",
    "genre_groups = create_genre_groups(trimmed_genre_links)\n",
    "for g in genre_groups:\n",
    "    if len(g) > 3:\n",
    "        print(g)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:53:09.714391Z",
     "start_time": "2021-11-30T18:53:09.691456Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-fb4b75a315ee>, line 52)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-fb4b75a315ee>\"\u001b[1;36m, line \u001b[1;32m52\u001b[0m\n\u001b[1;33m    if isdisjoint()\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class GroupClassifier():\n",
    "    # For subsequently lower thresholds, attempt to have a user-input name for each group.\n",
    "    # Remember group names for future groups, and summarise results using them.\n",
    "    def __init__(self, full_gmap, threshold_start=0.9, threshold_cap=0.1, threshold_step=0.1, group_min_size=5):\n",
    "        self.gmap = full_gmap\n",
    "        self.threshold_start = threshold_start\n",
    "        self.threshold_cap = threshold_cap\n",
    "        self.threshold_step = threshold_step\n",
    "        self.group_min_size = group_min_size\n",
    "        self.named_groups = []\n",
    "        self.threshold_groups = {}\n",
    "        self.main()\n",
    "    \n",
    "        \n",
    "    def get_groups(self, threshold):\n",
    "        trimmed_gmap = apply_threshold(self.gmap, threshold)\n",
    "        genre_groups = create_genre_groups(trimmed_gmap)\n",
    "        return genre_groups\n",
    "        \n",
    "        \n",
    "    def get_full_groups(self):\n",
    "        full_group_list = []\n",
    "        for fg in self.named_groups:\n",
    "            full_group = list(fg)\n",
    "            while True:\n",
    "                for index in range(len(full_group)):\n",
    "                    element = full_group[index]\n",
    "                    if type(element) == \"int\":\n",
    "                        del full_group[index]\n",
    "                        full_group += self.named_groups[index]\n",
    "                        continue\n",
    "                        \n",
    "                # If we get here, there are no more numbers left\n",
    "                # I have checked that there are no genre names that can be interpreted as numbers\n",
    "                break\n",
    "                \n",
    "            full_group_list.append(full_group)\n",
    "            \n",
    "        return full_group_list\n",
    "                \n",
    "\n",
    "    def main(self):\n",
    "        # Get original clusters\n",
    "        threshold = self.threshold_start\n",
    "        \n",
    "        for threshold in range(self.threshold_start, self.threshold_cap + 0.01, self.threshold_step):\n",
    "            print(threshold)\n",
    "            new_clusters = self.check_clusters(threshold)\n",
    "            \n",
    "            for cluster in new_clusters:\n",
    "                for group in self.named_groups:\n",
    "                    if isdisjoint()\n",
    "            \n",
    "            self.threshold_groups[threshold] = new_clusters\n",
    "            threshold = round(self.threshold_step)\n",
    "            threshold -= self.threshold_step\n",
    "        \n",
    "    \n",
    "    def check_clusters(self, threshold):\n",
    "        current_group_list = [g for g in self.get_groups(threshold) if len(g) >= self.group_min_size]\n",
    "        \n",
    "        full_group_list = self.get_full_groups()\n",
    "        new_groups = []\n",
    "        \n",
    "        for current_group in current_group_list:\n",
    "            group = current_group.copy()\n",
    "            subgroups = []\n",
    "            \n",
    "            overlap_found = False\n",
    "            while True:\n",
    "                overlap_groups = [(n, g) for n, g in enumerate(full_group_list) if len(group.intersection(g)) > 0]\n",
    "                \n",
    "                if len(overlap_groups) == 0:\n",
    "                    # Current group is not comprised of any subgroups\n",
    "                    break\n",
    "                \n",
    "                max_group_index, max_group = max(overlap_groups, key=lambda x: len(x[1]))\n",
    "                \n",
    "                subgroups.append(max_group_index)\n",
    "                group -= set(max_group)\n",
    "                overlap_found = True\n",
    "            \n",
    "            # There are now 4 scenarios:\n",
    "            # 1) If len(subgroups) == 0, it's a new cluster\n",
    "            # 2) If len(subgroups) >= 2, it's a merging of clusters\n",
    "            # 3) If len(subgroups) == 1, and len(group) > 0, it is an extension of an exisiting cluster\n",
    "            # 4) If len(subgroups) == 1, and len(group) == 0, it IS an existing cluster.\n",
    "            # Secnario 4 is the only scenario where we don't save the cluster.\n",
    "            \n",
    "            if (len(subgroups) == 1) and (len(group) == 0):\n",
    "                # Scenario 4\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                # Scenarios 1-3\n",
    "                # Add subgroups to cluster\n",
    "                group.update(subgroups)\n",
    "                self.named_groups.append(group)\n",
    "                new_groups.append(group)\n",
    "                \n",
    "        self.threshold_groups[threshold] = new_groups\n",
    "        return new_groups\n",
    "    \n",
    "    \n",
    "    def unfold_group(self, group):\n",
    "        for i in range(len(group)):\n",
    "            element = group[i]\n",
    "            if type(element) == type(1):\n",
    "                group[i] = self.unfold_group_by_index(element)\n",
    "        return group\n",
    "        \n",
    "        \n",
    "    def unfold_group_by_index(self, group_index):\n",
    "        group = list(self.named_groups[group_index].copy())\n",
    "        return self.unfold_group(group)\n",
    "        \n",
    "    \n",
    "    def get_threshold_indices(self):\n",
    "        keys = self.threshold_groups.keys()\n",
    "        for i in range(len(keys)):\n",
    "            print(f\"{i}: {keys[i]}\")\n",
    "    \n",
    "    def get_threshold_groups(self, index):\n",
    "        key = self.threshold_groups.keys()[index]\n",
    "        for i in range(index, -1, -1):\n",
    "            # For each group in current threshold:\n",
    "            #     Unfold group\n",
    "            #     Check if the group has any overlap with existing groups in the current list\n",
    "            #     If not, add to the current list\n",
    "        \n",
    "    def flatten(self, group):\n",
    "        output = []\n",
    "        for e in arr:\n",
    "            if isinstance(e, list) or isinstance(e, set):\n",
    "                print(e)\n",
    "                output += flatt(e)\n",
    "            else:\n",
    "                output.append(e)\n",
    "        return output\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "GC = GroupClassifier(normed_genre_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.902244Z",
     "start_time": "2021-11-30T18:52:04.109Z"
    }
   },
   "outputs": [],
   "source": [
    "GC.threshold_groups[0.5000000000000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.904240Z",
     "start_time": "2021-11-30T18:52:04.111Z"
    }
   },
   "outputs": [],
   "source": [
    "len(GC.named_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.905237Z",
     "start_time": "2021-11-30T18:52:04.113Z"
    }
   },
   "outputs": [],
   "source": [
    "GC.named_groups[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.907241Z",
     "start_time": "2021-11-30T18:52:04.115Z"
    }
   },
   "outputs": [],
   "source": [
    "print(GC.unfold_group(154))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.908228Z",
     "start_time": "2021-11-30T18:52:04.117Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Current Groups:\")\n",
    "for g in current_group_list:\n",
    "    print(g)\n",
    "print(\"===\\n\")\n",
    "\n",
    "full_group_list = []\n",
    "for full_group in all_group_list:\n",
    "    while True:\n",
    "        for index in range(len(full_group)):\n",
    "            element = full_group[index]\n",
    "            if type(element) == \"int\":\n",
    "                del full_group[index]\n",
    "                full_group += all_group_list[index]\n",
    "                continue\n",
    "        # If we get here, there are no more numbers left\n",
    "        # We have checked that no genre names can be interpreted as numbers\n",
    "        break\n",
    "    full_group_list.append(full_group)\n",
    "\n",
    "print(\"Existing Groups:\")\n",
    "for g in full_group_list:\n",
    "    print(g)\n",
    "print(\"===\\n\")\n",
    "    \n",
    "for current_group in current_group_list:\n",
    "    print(\"Original group:\")\n",
    "    print(current_group)\n",
    "    group = current_group.copy()\n",
    "    subgroups = []\n",
    "    \n",
    "    overlap_found = False\n",
    "    while True:\n",
    "        overlap_groups = [(n, g) for n, g in enumerate(full_group_list) if len(group.intersection(g)) > 0]\n",
    "        if len(overlap_groups) == 0:\n",
    "            print(\"no overlap groups\")\n",
    "            break\n",
    "        max_group_index, max_group = max(overlap_groups, key=lambda x: len(x[1]))\n",
    "        print(f\"mgi: {max_group_index}, mg: {max_group}\")\n",
    "        if len(max_group) == 1:\n",
    "            break\n",
    "        subgroups.append(max_group_index)\n",
    "        print(max_group)\n",
    "        group -= set(max_group)\n",
    "        overlap_found = True\n",
    "    \n",
    "    if overlap_found:  \n",
    "        print(\"Subgroups:\")\n",
    "        print(subgroups)\n",
    "        print(\"Leftovers:\")\n",
    "        print(group)\n",
    "        print(\"Final outcome:\")\n",
    "        group.update(subgroups)\n",
    "        print(group)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.910225Z",
     "start_time": "2021-11-30T18:52:04.119Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(9, 1, -1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.912218Z",
     "start_time": "2021-11-30T18:52:04.121Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [[1,2,3,4,[9,10,[11,12]]],[5,6,7,8,{1,2,3}]]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.913216Z",
     "start_time": "2021-11-30T18:52:04.123Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatt(arr):\n",
    "    output = []\n",
    "    for e in arr:\n",
    "        if isinstance(e, list) or isinstance(e, set):\n",
    "            print(e)\n",
    "            output += flatt(e)\n",
    "        else:\n",
    "            output.append(e)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.914212Z",
     "start_time": "2021-11-30T18:52:04.125Z"
    }
   },
   "outputs": [],
   "source": [
    "flatt(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.915211Z",
     "start_time": "2021-11-30T18:52:04.127Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.917204Z",
     "start_time": "2021-11-30T18:52:04.128Z"
    }
   },
   "outputs": [],
   "source": [
    "clustering = SpectralClustering(n_clusters=10, n_components=300, assign_labels=\"discretize\",\n",
    "                                random_state=0, affinity=\"precomputed\")\n",
    "clustering.fit(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.918201Z",
     "start_time": "2021-11-30T18:52:04.130Z"
    }
   },
   "outputs": [],
   "source": [
    "count = {}\n",
    "for i in clustering.labels_:\n",
    "    if i not in count:\n",
    "        count[i] = 0\n",
    "    count[i] += 1\n",
    "group_sizes = {}\n",
    "for i in count:\n",
    "    if count[i] not in group_sizes:\n",
    "        group_sizes[count[i]] = 0\n",
    "    group_sizes[count[i]] += 1\n",
    "print(sorted(group_sizes.items(), key=lambda x: x[0], reverse=True))\n",
    "print(count)\n",
    "print(len(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.920196Z",
     "start_time": "2021-11-30T18:52:04.132Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in range(1, 50):\n",
    "    for i in range(len(clustering.labels_)):\n",
    "        if clustering.labels_[i] == k:\n",
    "            print(df.index[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.921194Z",
     "start_time": "2021-11-30T18:52:04.134Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 2000\n",
    "j = 50\n",
    "clustering.labels_[i:i+j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.923188Z",
     "start_time": "2021-11-30T18:52:04.136Z"
    }
   },
   "outputs": [],
   "source": [
    "clustering.labels_[2002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T18:52:16.924186Z",
     "start_time": "2021-11-30T18:52:04.138Z"
    }
   },
   "outputs": [],
   "source": [
    "df.index[2002]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
